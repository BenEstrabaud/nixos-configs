{ config, pkgs, lib, ... }:

let
  # ---------- Samba operator manifest ----------
  # The samba-operator has no Helm chart — it ships a single all-in-one manifest.
  # We use the upstream v0.8 manifest as the base (CRDs, RBAC, Namespace, etc.)
  # and patch the operator container image to our fork which fixes the smbmetrics
  # --port bug (https://github.com/BenEstrabaud/samba-operator, tag v0.8-be-0).
  #
  # pkgs.runCommand is a sandbox-safe derivation: the inner fetchurl is a
  # fixed-output derivation (hash known), so network access is permitted there.
  sambaOperatorManifest = pkgs.runCommand "samba-operator-manifest.yaml" {} ''
    ${pkgs.gnused}/bin/sed \
      's|quay\.io/samba\.org/samba-operator:v0\.8|ghcr.io/benestrabaud/samba-operator:v0.8-be-0|g' \
      ${pkgs.fetchurl {
        url = "https://github.com/samba-in-kubernetes/samba-operator/releases/download/v0.8/samba-operator-v0.8-default.yaml";
        hash = "sha256-f7sU3XfSY4qXCW97wSuWcRaJFQlkYR9mvpSy3yKYTqc=";
      }} > $out
  '';

  # ---------- MetalLB IP pool ----------
  # Set this to a free range on your home LAN (outside your router's DHCP range).
  # Services of type LoadBalancer (e.g. the Samba Time Machine share) will
  # receive an IP from this range via ARP/L2 advertisement.
  metallbIpRange = "192.168.1.200-192.168.1.250";

  # ---------- Samba ----------
  # Passwords are embedded in K8s Secret YAMLs and deployed via k3s auto-deploy.
  # WARNING: These values land in /nix/store which is world-readable on the NAS.
  # Acceptable for a single-user home NAS; use a secrets manager for stricter needs.
  sambaTimemachinePassword = "REPLACE-TIMEMACHINE-PASSWORD";
  sambaStoragePassword     = "REPLACE-STORAGE-PASSWORD";
  # PVC size for the general-purpose storage share.
  # local-path-provisioner does not enforce this limit; it is advisory only.
  storageShareSize = "10Ti";

  # Generate the MetalLB IPAddressPool + L2Advertisement manifest from the
  # variable above so it stays a single source of truth.
  metallbConfig = pkgs.writeText "metallb-config.yaml" ''
    # Auto-generated by services.nix — edit metallbIpRange to change the pool.
    apiVersion: metallb.io/v1beta1
    kind: IPAddressPool
    metadata:
      name: default-pool
      namespace: metallb-system
    spec:
      addresses:
      - ${metallbIpRange}
    ---
    apiVersion: metallb.io/v1beta1
    kind: L2Advertisement
    metadata:
      name: default
      namespace: metallb-system
    spec:
      ipAddressPools:
      - default-pool
  '';

  # ---------- Samba user secrets ----------
  # sambacc JSON format: the samba-operator reads users.json from the Secret.
  timemachineUsersSecret = pkgs.writeText "timemachine-users-secret.yaml" ''
    apiVersion: v1
    kind: Secret
    metadata:
      name: timemachine-users
      namespace: samba
    stringData:
      users.json: '{"samba-container-config":"v0","users":{"all_entries":[{"name":"timemachine","password":"${sambaTimemachinePassword}"}]}}'
  '';

  storageUsersSecret = pkgs.writeText "storage-users-secret.yaml" ''
    apiVersion: v1
    kind: Secret
    metadata:
      name: storage-users
      namespace: samba
    stringData:
      users.json: '{"samba-container-config":"v0","users":{"all_entries":[{"name":"storage","password":"${sambaStoragePassword}"}]}}'
  '';

  # ---------- Storage share resources ----------
  sambaStorageResources = pkgs.writeText "samba-storage.yaml" ''
    # PVC, SmbSecurityConfig, and SmbShare for the general-purpose storage share.
    # Generated from storageShareSize in services.nix.
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: storage
      namespace: samba
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: ${storageShareSize}
    ---
    apiVersion: samba-operator.samba.org/v1alpha1
    kind: SmbSecurityConfig
    metadata:
      name: samba-security-storage
      namespace: samba
    spec:
      mode: user
      users:
        secret: storage-users
        key: users.json
    ---
    apiVersion: samba-operator.samba.org/v1alpha1
    kind: SmbShare
    metadata:
      name: storage
      namespace: samba
    spec:
      shareName: "storage"
      readOnly: false
      browseable: true
      storage:
        pvc:
          name: storage
      commonConfig: samba-common
      securityConfig: samba-security-storage
  '';

  # ---------- Dynamic Avahi publisher ----------
  # Polls k3s for LoadBalancer services in the samba namespace and publishes
  # mDNS records dynamically as IPs are assigned by MetalLB.  This removes the
  # need for a hardcoded sambaLbIp — every share gets whatever IP MetalLB picks,
  # and macOS auto-discovers it without any manual configuration.
  #
  # For each service with a live external IP the script:
  #   • runs avahi-publish -a <name>-samba.local <ip>  (keeps the A record alive)
  #   • writes /etc/avahi/services/samba-<name>.service (service-type records;
  #     avahi-daemon reloads via inotify)
  # Timemachine shares additionally get _device-info._tcp and _adisk._tcp so
  # macOS Time Machine auto-discovers them.
  sambaAvahiPublisher = pkgs.writeShellScript "samba-avahi-publisher" ''
    set -euo pipefail

    SERVICES_DIR="/etc/avahi/services"
    declare -A pids=()       # share-name → PID of avahi-publish -a
    declare -A known_ips=()  # share-name → last-seen external IP

    cleanup() {
      for name in "''${!pids[@]}"; do
        kill "''${pids[$name]}" 2>/dev/null || true
      done
      for name in "''${!known_ips[@]}"; do
        rm -f "''${SERVICES_DIR}/samba-''${name}.service"
      done
    }
    trap cleanup EXIT TERM INT

    publish_share() {
      local name="$1" ip="$2"
      local hostname="''${name}-samba.local"

      # Restart avahi-publish -a for this hostname → IP mapping
      if [[ -v "pids[$name]" ]]; then
        kill "''${pids[$name]}" 2>/dev/null || true
        unset "pids[$name]"
      fi
      avahi-publish -a --no-fail "''${hostname}" "''${ip}" &
      pids[$name]=$!

      # Write service XML (avahi-daemon picks it up via inotify)
      local svcfile="''${SERVICES_DIR}/samba-''${name}.service"
      local tmpfile="''${svcfile}.tmp.$$"
      {
        printf '<?xml version="1.0" standalone='"'"'no'"'"'?>\n'
        printf '<!DOCTYPE service-group SYSTEM "avahi-service.dtd">\n'
        printf '<service-group>\n'
        printf '  <name replace-wildcards="yes">NAS %s</name>\n' "''${name}"
        printf '  <service>\n'
        printf '    <host-name>%s</host-name>\n' "''${hostname}"
        printf '    <type>_smb._tcp</type>\n'
        printf '    <port>445</port>\n'
        printf '  </service>\n'
        if [[ "''${name}" == *timemachine* ]]; then
          printf '  <service>\n'
          printf '    <host-name>%s</host-name>\n' "''${hostname}"
          printf '    <type>_device-info._tcp</type>\n'
          printf '    <port>0</port>\n'
          printf '    <txt-record>model=TimeCapsule8,119</txt-record>\n'
          printf '  </service>\n'
          printf '  <service>\n'
          printf '    <host-name>%s</host-name>\n' "''${hostname}"
          printf '    <type>_adisk._tcp</type>\n'
          printf '    <txt-record>dk0=adVN=%s,adVF=0x82</txt-record>\n' "''${name}"
          printf '    <txt-record>sys=waMa=0,adVF=0x100</txt-record>\n'
          printf '  </service>\n'
        fi
        printf '</service-group>\n'
      } > "''${tmpfile}"
      mv "''${tmpfile}" "''${svcfile}"
      echo "[samba-avahi-publisher] Published ''${name} → ''${hostname} (''${ip})"
    }

    unpublish_share() {
      local name="$1"
      if [[ -v "pids[$name]" ]]; then
        kill "''${pids[$name]}" 2>/dev/null || true
        unset "pids[$name]"
      fi
      rm -f "''${SERVICES_DIR}/samba-''${name}.service"
      echo "[samba-avahi-publisher] Unpublished ''${name}"
    }

    echo "[samba-avahi-publisher] Starting"
    mkdir -p "''${SERVICES_DIR}"

    while true; do
      unset current_ips; declare -A current_ips=()
      while IFS=$'\t' read -r svc_name svc_ip; do
        [[ -z "''${svc_name}" || -z "''${svc_ip}" || "''${svc_ip}" == "null" ]] && continue
        current_ips["''${svc_name}"]="''${svc_ip}"
      done < <(k3s kubectl -n samba get svc \
        -o jsonpath='{range .items[?(@.spec.type=="LoadBalancer")]}{.metadata.name}{"\t"}{.status.loadBalancer.ingress[0].ip}{"\n"}{end}' \
        2>/dev/null || true)

      for name in "''${!current_ips[@]}"; do
        ip="''${current_ips[$name]}"
        if [[ ! -v "known_ips[$name]" || "''${known_ips[$name]}" != "''${ip}" ]]; then
          publish_share "''${name}" "''${ip}"
          known_ips[$name]="''${ip}"
        fi
      done

      for name in "''${!known_ips[@]}"; do
        if [[ ! -v "current_ips[$name]" ]]; then
          unpublish_share "''${name}"
          unset "known_ips[$name]"
        fi
      done

      sleep 10
    done
  '';
in
{
  # ---------- Networking ----------
  networking.hostName = "nas";

  # ---------- Firewall ----------
  networking.firewall = {
    enable = true;
    allowedTCPPorts = [
      22    # SSH
      6443  # k3s API server
    ];
    # Trust the CNI interfaces so pod-to-pod traffic is not blocked
    trustedInterfaces = [ "cni0" "flannel.1" ];
  };

  # ---------- SSH ----------
  services.openssh = {
    enable = true;
    settings = {
      PasswordAuthentication = false;
      KbdInteractiveAuthentication = false;
      PermitRootLogin = "no";
    };
  };

  # ---------- User ----------
  users.mutableUsers = false; # declarative-only user management

  users.users.ben = {
    isNormalUser = true;
    extraGroups = [ "wheel" ];
    openssh.authorizedKeys.keys = [
      # Paste your public key here, e.g.:
      # "ssh-ed25519 AAAAC3Nza... ben@workstation"
    ];
  };

  # Allow passwordless sudo for wheel (useful for remote admin via SSH key)
  security.sudo.wheelNeedsPassword = false;

  # ---------- Shell ----------
  # Enable bash tab-completion for all installed packages.
  programs.bash.enableCompletion = true;

  # kubectl completion via k3s.
  # Also installs a 'kubectl' alias so bare `kubectl` works alongside `k3s kubectl`.
  programs.bash.interactiveShellInit = ''
    if command -v k3s &>/dev/null; then
      alias kubectl='k3s kubectl'
      source <(k3s kubectl completion bash 2>/dev/null) || true
      # Register completion for the 'kubectl' alias as well
      complete -o default -F __start_kubectl kubectl 2>/dev/null || true
    fi
  '';

  # ---------- k3s ----------
  services.k3s = {
    enable = true;
    role = "server";
    # Single-node cluster — no external datastore needed.
    # k3s bundles containerd, flannel, CoreDNS, and local-path-provisioner.
    # local-path-provisioner is the default StorageClass; PVCs are
    # dynamically provisioned under the path below.
    #
    # servicelb is disabled in favour of MetalLB (see manifests/metallb.yaml).
    extraFlags = toString [
      "--default-local-storage-path /data/kubernetes"
      "--disable=servicelb"   # MetalLB replaces the built-in load balancer
      "--disable=traefik"     # No ingress controller needed; services use MetalLB IPs directly
    ];
  };

  # Required for pod networking
  boot.kernel.sysctl."net.ipv4.ip_forward" = 1;

  # ---------- Monitoring ----------
  # Symlink Helm manifests into the k3s auto-deploy directory.
  # k3s picks these up and installs the charts automatically.
  systemd.tmpfiles.rules = [
    "d /var/lib/rancher/k3s/server/manifests 0755 root root -"

    # Monitoring stack
    "L+ /var/lib/rancher/k3s/server/manifests/monitoring-ns.yaml - - - - ${./../../manifests/monitoring-ns.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/kube-prometheus-stack.yaml - - - - ${./../../manifests/kube-prometheus-stack.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/thanos.yaml - - - - ${./../../manifests/thanos.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/pvc-alerts.yaml - - - - ${./../../manifests/pvc-alerts.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/smartctl-exporter.yaml - - - - ${./../../manifests/smartctl-exporter.yaml}"

    # NetworkPolicies (default-deny + explicit allows per component)
    "L+ /var/lib/rancher/k3s/server/manifests/netpol-monitoring.yaml - - - - ${./../../manifests/netpol-monitoring.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/netpol-samba.yaml - - - - ${./../../manifests/netpol-samba.yaml}"

    # MetalLB load balancer
    "L+ /var/lib/rancher/k3s/server/manifests/metallb.yaml - - - - ${./../../manifests/metallb.yaml}"
    # metallb-config.yaml is generated from metallbIpRange above (not a static file)
    "L+ /var/lib/rancher/k3s/server/manifests/metallb-config.yaml - - - - ${metallbConfig}"

    # Samba operator + Time Machine share
    # samba-operator.yaml is fetched from GitHub at build time (fixed-output derivation)
    "L+ /var/lib/rancher/k3s/server/manifests/samba-ns.yaml - - - - ${./../../manifests/samba-ns.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/samba-operator.yaml - - - - ${sambaOperatorManifest}"
    "L+ /var/lib/rancher/k3s/server/manifests/samba-share.yaml - - - - ${./../../manifests/samba-share.yaml}"

    # Samba user secrets (generated from Nix variables; passwords land in /nix/store)
    "L+ /var/lib/rancher/k3s/server/manifests/timemachine-users-secret.yaml - - - - ${timemachineUsersSecret}"
    "L+ /var/lib/rancher/k3s/server/manifests/storage-users-secret.yaml - - - - ${storageUsersSecret}"

    # Storage share (PVC + SmbSecurityConfig + SmbShare; size from storageShareSize)
    "L+ /var/lib/rancher/k3s/server/manifests/samba-storage.yaml - - - - ${sambaStorageResources}"

    # smbmetrics Prometheus exporter for Samba
    "L+ /var/lib/rancher/k3s/server/manifests/smbmetrics.yaml - - - - ${./../../manifests/smbmetrics.yaml}"
    "L+ /var/lib/rancher/k3s/server/manifests/samba-dashboard.yaml - - - - ${./../../manifests/samba-dashboard.yaml}"
  ];

  # Host-level SMART monitoring (runs independently of k8s)
  services.smartd = {
    enable = true;
    autodetect = true;
  };

  # ---------- Avahi / mDNS ----------
  # Enables mDNS so macOS auto-discovers Samba shares in Finder and Time Machine.
  # Service records and A records are published dynamically by samba-avahi-publisher
  # (see systemd.services below) — no hardcoded IP needed.
  services.avahi = {
    enable = true;
    openFirewall = true;   # opens UDP 5353 (mDNS)
    publish = {
      enable = true;
      addresses = true;
      workstation = true;
    };
    # Service files are managed dynamically by samba-avahi-publisher.service
  };

  # ---------- Dynamic Samba mDNS publisher ----------
  # Watches the samba namespace for LoadBalancer services with assigned IPs and
  # publishes per-share mDNS records dynamically.  Each share gets a hostname of
  # the form <name>-samba.local pointing to its MetalLB IP.  Timemachine shares
  # additionally advertise _device-info._tcp and _adisk._tcp so macOS Time Machine
  # finds them automatically without a hardcoded IP in the NixOS config.
  systemd.services.samba-avahi-publisher = {
    description = "Dynamically publish Samba shares via Avahi mDNS";
    after    = [ "avahi-daemon.service" "k3s.service" "network-online.target" ];
    wants    = [ "avahi-daemon.service" "network-online.target" ];
    wantedBy = [ "multi-user.target" ];
    path     = with pkgs; [ k3s avahi ];
    serviceConfig = {
      Type       = "simple";
      Restart    = "always";
      RestartSec = "10s";
      ExecStart  = "${sambaAvahiPublisher}";
    };
  };

  # ---------- Auto-upgrade ----------
  # Automatically updates NixOS (and thus k3s, which is a nixpkgs package) weekly.
  #
  # The flake URL below assumes the config is checked out at /etc/nixos.
  # If the repo is hosted on GitHub, replace with:
  #   flake = "github:youruser/nixos-configs";
  # and remove the --update-input / --commit-lock-file flags (the remote
  # flake.lock is updated by pushing to the repo instead).
  #
  # Helm chart versions in manifests/ are NOT auto-bumped by this mechanism —
  # review and update them manually when new chart releases are available.
  system.autoUpgrade = {
    enable = true;
    flake = "/etc/nixos";
    flags = [
      "--update-input" "nixpkgs"
    ];
    dates = "Sun 03:00";          # Weekly on Sunday at 03:00
    randomizedDelaySecs = 1800;   # ±30-minute jitter to avoid thundering herd
    allowReboot = true;           # Reboot automatically after kernel updates
    rebootWindow = {
      lower = "02:00";
      upper = "06:00";
    };
  };

  # ---------- Packages ----------
  environment.systemPackages = with pkgs; [
    vim
    htop
    git
    k3s           # provides kubectl via `k3s kubectl` (aliased to `kubectl` above)
    xfsprogs      # XFS management (xfs_repair, xfs_growfs, etc.)
    mdadm
    lvm2
    smartmontools # smartctl for manual drive inspection
    lm_sensors    # sensors for manual temp readings
  ];

  system.stateVersion = "24.11";
}
